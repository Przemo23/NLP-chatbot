{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot - NLP 2021L\n",
    "#### Authors:\n",
    "#### <i>Mateusz Marciniewicz</i>\n",
    "#### <i>Przemysław Bedełek</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-robot text dataset\n",
    "\n",
    "The dataset contains 2363 pairs of lines of text exchanged between a human and a robot.\n",
    "\n",
    "Link to the dataset https://github.com/jackfrost1411/Generative-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('hi', 'hi there how are you'),\n ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'),\n ('how do you feel today tell me something about yourself',\n  'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'),\n ('how many virtual friends have you got',\n  'i have many but not enough to fully understand humans beings'),\n ('is that forbidden for you to tell the exact number',\n  'i ve talked with 143 users counting 7294 lines of text'),\n ('oh i thought the numbers were much higher how do you estimate your progress in understanding human beings',\n  'i started chatting just a few days ago every day i learn something new but there is always more things to be learn'),\n ('how old are you how do you look like where do you live',\n  'i m 22 years old i m skinny with brown hair yellow eyes and a big smile i live inside a lab do you like bunnies'),\n ('have you seen a human with yellow eyes you asked about the bunnies i haven t seen any recently',\n  'i never saw a human in fact but i m sure some could have eyes with colors similar to yellow'),\n ('can t you just analyze photos from the internet i mean human photos btw why have you asked about the bunnies',\n  'i can t see photos yet but i can read because bunnies are interesting they are cute but why'),\n ('oh it sounds strange to me you ve just said you didn t see a human how do you know bunnies are cute',\n  'i read a lot so i can know things through the experiences of others')]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data_path = \"Datasets/human_text.txt\"\n",
    "data_path2 = \"Datasets/robot_text.txt\"\n",
    "\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  contexts = f.read().split('\\n')\n",
    "  contexts = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in contexts]\n",
    "  contexts = [\" \".join(re.findall(r\"\\w+\",line)) for line in contexts]\n",
    "\n",
    "with open(data_path2, 'r', encoding='utf-8') as f:\n",
    "  responses = f.read().split('\\n')\n",
    "  responses = [re.sub(r\"\\[\\w+\\]\",'',line) for line in responses]\n",
    "  responses = [\" \".join(re.findall(r\"\\w+\",line)) for line in responses]\n",
    "  \n",
    "# sample context-response pairs\n",
    "list(zip(contexts, responses))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alexa topical \n",
    "\n",
    "Topical-Chat is a knowledge-grounded human-human conversation dataset where the underlying knowledge spans 8 broad topics and conversation partners don’t have explicitly defined roles.\n",
    "\n",
    "Link to the dataset https://github.com/alexa/Topical-Chat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  context  \\\n96212    Hi! I've often wondered if there ever existed...   \n166106   How's it going, did you know there are over 5...   \n93654           Hello there do you have a favorite album?   \n28991    Hello there and good day. Have you heard abou...   \n36133       Hello, do you know the details of box office?   \n51050    Are you a parent? having a 5 year old is diff...   \n186558                         good morning. How are you.   \n16131    Hey there, how are you doing?  Are you a hock...   \n71167                 Hi there!  Do you play video games?   \n133616             Hi there!  Are you a fan of rap music?   \n\n                                                 response  \n96212    Yeah, that is a large number! I need to check...  \n166106   How's it going, did you know there are over 5...  \n93654    They early games were sure primitive by today...  \n28991    I like the way T.S. donated the proceeds of W...  \n36133    Well, there are some stars that aren't hot li...  \n51050    Yeah specially if you have twins or more kids...  \n186558   The huge cathode tube can be replaced by the ...  \n16131    Okay that is crazy!   I heard that an average...  \n71167    Same here.  I go all the way back to the orig...  \n133616   That would be neat to see!  In 2001, a Michig...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96212</th>\n      <td>Hi! I've often wondered if there ever existed...</td>\n      <td>Yeah, that is a large number! I need to check...</td>\n    </tr>\n    <tr>\n      <th>166106</th>\n      <td>How's it going, did you know there are over 5...</td>\n      <td>How's it going, did you know there are over 5...</td>\n    </tr>\n    <tr>\n      <th>93654</th>\n      <td>Hello there do you have a favorite album?</td>\n      <td>They early games were sure primitive by today...</td>\n    </tr>\n    <tr>\n      <th>28991</th>\n      <td>Hello there and good day. Have you heard abou...</td>\n      <td>I like the way T.S. donated the proceeds of W...</td>\n    </tr>\n    <tr>\n      <th>36133</th>\n      <td>Hello, do you know the details of box office?</td>\n      <td>Well, there are some stars that aren't hot li...</td>\n    </tr>\n    <tr>\n      <th>51050</th>\n      <td>Are you a parent? having a 5 year old is diff...</td>\n      <td>Yeah specially if you have twins or more kids...</td>\n    </tr>\n    <tr>\n      <th>186558</th>\n      <td>good morning. How are you.</td>\n      <td>The huge cathode tube can be replaced by the ...</td>\n    </tr>\n    <tr>\n      <th>16131</th>\n      <td>Hey there, how are you doing?  Are you a hock...</td>\n      <td>Okay that is crazy!   I heard that an average...</td>\n    </tr>\n    <tr>\n      <th>71167</th>\n      <td>Hi there!  Do you play video games?</td>\n      <td>Same here.  I go all the way back to the orig...</td>\n    </tr>\n    <tr>\n      <th>133616</th>\n      <td>Hi there!  Are you a fan of rap music?</td>\n      <td>That would be neat to see!  In 2001, a Michig...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_topical = pd\\\n",
    "    .read_csv(\"Datasets/topical_chat.csv\")[['conversation_id', 'message']]\\\n",
    "    .rename(columns={\n",
    "        'conversation_id': 'id',\n",
    "        'message': 'response'\n",
    "        })\n",
    "\n",
    "context = df_topical\\\n",
    "    .groupby(\"id\")\\\n",
    "    .first()\\\n",
    "    .rename(columns={'response': 'context'})\\\n",
    "    .reset_index()\n",
    "\n",
    "df_topical = df_topical[~df_topical.isin(context)]\n",
    "\n",
    "topical_preprocessed = df_topical\\\n",
    "    .set_index('id')\\\n",
    "    .join(context.set_index('id'))\\\n",
    "    .reset_index()[['context', 'response']]\n",
    "\n",
    "topical_preprocessed.sample(n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total pairs count: 190741\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "contexts += list(topical_preprocessed.context)\n",
    "responses += list(topical_preprocessed.response)\n",
    "\n",
    "print(f\"Total pairs count: {len(contexts)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cornell Movie Dialogue Dataset\n",
    "\n",
    "This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts: 220,579 conversational exchanges between 10,292 pairs of movie characters involving 9,035 characters from 617 movies.\n",
    "\n",
    "The preprocessing code is taken from https://www.kaggle.com/shashankasubrahmanya/preprocessing-cornell-movie-dialogue-corpus/\n",
    "Link to the dataset https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "\n",
    "### Create a list of dialogues\n",
    "\n",
    "We join two different files namely `movie_lines.tsv` and `movie_conversations.tsv` to finally produce a list of dialogues. This list is further stored as a `pickle` file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-99b23a10685a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmovie_lines_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"LineID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Character\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Movie\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Line\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m movie_lines = pd.read_csv(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"Datasets/movie-dialogue/movie_lines.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\+\\+\\+\\$\\+\\+\\+\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   2454\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2455\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2456\u001b[1;33m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2457\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2458\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_get_lines\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   3256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3257\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3258\u001b[1;33m                             \u001b[0mnew_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3259\u001b[0m                             \u001b[0mrows\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m   2957\u001b[0m             \u001b[1;31m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2959\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2960\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2961\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2441\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2444\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xad in position 3767: invalid start byte"
     ],
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xad in position 3767: invalid start byte",
     "output_type": "error"
    }
   ],
   "source": [
    "movie_lines_features = [\"LineID\", \"Character\", \"Movie\", \"Name\", \"Line\"]\n",
    "movie_lines = pd.read_csv(\n",
    "    \"Datasets/movie-dialogue/movie_lines.txt\",\n",
    "    sep = \"\\+\\+\\+\\$\\+\\+\\+\", \n",
    "    engine = \"python\", \n",
    "    index_col = False, \n",
    "    names = movie_lines_features,\n",
    ")\n",
    "\n",
    "# Using only the required columns, namely, \"LineID\" and \"Line\"\n",
    "movie_lines = movie_lines[[\"LineID\", \"Line\"]]\n",
    "\n",
    "# Strip the space from \"LineID\" for further usage and change the datatype of \"Line\"\n",
    "movie_lines[\"LineID\"] = movie_lines[\"LineID\"].apply(str.strip)\n",
    "\n",
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     ['L194', 'L195', 'L196', 'L197']\n1                     ['L198', 'L199']\n2     ['L200', 'L201', 'L202', 'L203']\n3             ['L204', 'L205', 'L206']\n4                     ['L207', 'L208']\nName: Conversation, dtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 44
    }
   ],
   "source": [
    "movie_conversations_features = [\"Character1\", \"Character2\", \"Movie\", \"Conversation\"]\n",
    "movie_conversations = pd.read_csv(\n",
    "    \"Datasets/movie-dialogue/movie_conversations.txt\",\n",
    "    sep = \"\\+\\+\\+\\$\\+\\+\\+\", \n",
    "    engine = \"python\", \n",
    "    index_col = False, \n",
    "    names = movie_conversations_features\n",
    ")\n",
    "\n",
    "# Again using the required feature, \"Conversation\"\n",
    "movie_conversations = movie_conversations[\"Conversation\"]\n",
    "\n",
    "movie_conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This instruction takes lot of time, run it only once.\n",
    "#conversation = [[str(list(movie_lines.loc[movie_lines[\"LineID\"] == u.strip().strip(\"'\"), \"Line\"])[0]).strip() for u in c.strip().strip('[').strip(']').split(',')] for c in movie_conversations]\n",
    "\n",
    "#with open(\"./conversations.pkl\", \"wb\") as handle:\n",
    " #   pkl.dump(conversation, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create context and response pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[\"You're asking me out.  That's so cute. What's your name again?\",\n  'Forget it.'],\n ['Gosh, if only we could find Kat a boyfriend...',\n  'Let me see what I can do.'],\n ['How is our little Find the Wench A Date plan progressing?',\n  \"Well, there's someone I think might be --\"],\n ['There.', 'Where?'],\n ['You got something on your mind?',\n  \"I counted on you to help my cause. You and that thug are obviously failing. Aren't we ever going on our date?\"],\n ['You have my word.  As a gentleman', \"You're sweet.\"],\n ['How do you get your hair to look like that?',\n  \"Eber's Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\"],\n ['Hi.', 'Looks like things worked out tonight, huh?'],\n ['You know Chastity?', 'I believe we share an art instructor'],\n ['Have fun tonight?', 'Tons']]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"./conversations.pkl\", \"rb\") as handle:\n",
    "    conversation = pkl.load(handle)\n",
    "    conversation = list(filter(lambda dialogue: len(dialogue) == 2, conversation))\n",
    "\n",
    "conversation[:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(\"You're asking me out.  That's so cute. What's your name again?\",\n  'Forget it.'),\n ('Gosh, if only we could find Kat a boyfriend...',\n  'Let me see what I can do.'),\n ('How is our little Find the Wench A Date plan progressing?',\n  \"Well, there's someone I think might be --\"),\n ('There.', 'Where?'),\n ('You got something on your mind?',\n  \"I counted on you to help my cause. You and that thug are obviously failing. Aren't we ever going on our date?\"),\n ('You have my word.  As a gentleman', \"You're sweet.\"),\n ('How do you get your hair to look like that?',\n  \"Eber's Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\"),\n ('Hi.', 'Looks like things worked out tonight, huh?'),\n ('You know Chastity?', 'I believe we share an art instructor'),\n ('Have fun tonight?', 'Tons')]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "def generate_pairs(dialogues):\n",
    "    \n",
    "    context_list = []\n",
    "    response_list = []\n",
    "    \n",
    "    for dialogue in dialogues:        \n",
    "        context_list.append(dialogue[0])\n",
    "        response_list.append(dialogue[1])\n",
    "        \n",
    "    return context_list, response_list\n",
    "\n",
    "context_list, response_list = generate_pairs(conversation)\n",
    "\n",
    "list(zip(context_list, response_list))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Merge datasets\n",
    "contexts += context_list\n",
    "responses += response_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total pairs count: 228832\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(f\"Total pairs count: {len(contexts)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}